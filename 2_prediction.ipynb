{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS5242 Final Project : Prediction Notebook\n",
    "===\n",
    "\n",
    "*Murat Shagirov*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T10:30:19.848781Z",
     "start_time": "2020-11-01T10:30:19.771791Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T10:35:10.232933Z",
     "start_time": "2020-11-01T10:35:09.880741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:2\n",
      "dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from datautils import LoadTrainingData\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, utils, transforms as T\n",
    "\n",
    "from datautils import BatchUnnorm, Unnorm\n",
    "\n",
    "from nn import predict_check, predict_test # prediction function\n",
    "\n",
    "# check for CUDA device and set default dtype\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "dtype = torch.float32\n",
    "print(f'device: {device}\\ndtype: {dtype}')\n",
    "\n",
    "\n",
    "# # # # # # # Set this before running # # # # # # # # # #\n",
    "# Set CHECK_VAL_PRED to True if you want to verify train/validation set performances\n",
    "CHECK_VAL_PRED = True # : True/False\n",
    "\n",
    "# location of training ID-label pairs\n",
    "train_csv_path = './datasets/train_label.csv' # : str\n",
    "\n",
    "# Path to directory with training set images\n",
    "train_img_path = './datasets/train_image/train_image/' # : str\n",
    "\n",
    "# Path to save to/load models from\n",
    "models_path = '../../dataDIR/cs5242/' # path : str\n",
    "# model_fname = 'densenet121_ft_V1.pkl' # file name for desired model : str\n",
    "model_fname = 'densenet121_ft_512px_v2.pkl' # file name for desired model : str\n",
    "\n",
    "# !!! Path to directory with test dataset images !!!\n",
    "test_path = './datasets/test_image/test_image/' # : str\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T10:30:46.473893Z",
     "start_time": "2020-11-01T10:30:46.085133Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Plotting tools and settings\n",
    "# import matplotlib.pyplot as plt\n",
    "# # for plotting figures (report)\n",
    "# import matplotlib\n",
    "# plt.style.use('ggplot')\n",
    "# %matplotlib inline\n",
    "# matplotlib.rcParams['figure.figsize'] = (15,5) # use larger for presentation\n",
    "# matplotlib.rcParams['font.size']= 9 # use 14 for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T10:30:46.932087Z",
     "start_time": "2020-11-01T10:30:46.476598Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transforms\n",
    "# unnorm = Unnorm() # unnormalize a single RGB image\n",
    "# unnormb = BatchUnnorm() # unnormalize batch of images\n",
    "img_size = 512 # Input image  size\n",
    "\n",
    "# toPIL = T.ToPILImage()\n",
    "# Training data transforms\n",
    "transform = T.Compose([T.ToPILImage(),\n",
    "                       T.RandomRotation((-3,3)),\n",
    "                       T.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n",
    "                       T.RandomHorizontalFlip(),\n",
    "                       T.ToTensor(),\n",
    "                       T.ConvertImageDtype(dtype), \n",
    "                       T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# Test and Val data transforms\n",
    "val_transform = T.Compose([T.ToPILImage(),\n",
    "                           T.Resize(img_size),\n",
    "                           T.ToTensor(),\n",
    "                           T.ConvertImageDtype(dtype),\n",
    "                           T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "test_transform = val_transform\n",
    "# Loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T10:30:58.485182Z",
     "start_time": "2020-11-01T10:30:47.618153Z"
    }
   },
   "outputs": [],
   "source": [
    "# # # # # # # # # # # # # # # # # # # #\n",
    "# # Initiate and load desired model # #\n",
    "# # # # # # # # # # # # # # # # # # # #\n",
    "\n",
    "# Initiate default model (w/o weights) or download ImageNet pre-trained model from torchhub\n",
    "model_ft = models.densenet121(pretrained=False,progress=False)\n",
    "# change last FC layer\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "model_ft.classifier = nn.Linear(num_ftrs, 3)\n",
    "\n",
    "# Location for model's weights:\n",
    "DENSENET121_path = path.join(models_path, model_fname)\n",
    "model_ft.load_state_dict(torch.load(DENSENET121_path))\n",
    "# set model mode for prediction:\n",
    "model_ft.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T10:32:00.807208Z",
     "start_time": "2020-11-01T10:30:58.486927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: 931 samples. \n",
      "Validation dataset: 233 samples.\n",
      "Loading: train\n",
      "Loading: val\n",
      "Losses: {'train': 0.006019095726112451, 'val': 0.10522011947352064}\n",
      "Accuracies: {'train': tensor(0.9989), 'val': tensor(0.9785)}\n"
     ]
    }
   ],
   "source": [
    "if CHECK_VAL_PRED:\n",
    "    # Load and split original data into 80-20 Train-Val sets\n",
    "    np.random.seed(42) #seed np RNG for consistency\n",
    "    datasets = LoadTrainingData(train_csv_path, train_img_path, transform=transform,\n",
    "                                split=True, train_percent=80, val_transform=val_transform)\n",
    "\n",
    "    print(f\"Training dataset: {len(datasets['train'])} samples.\",\n",
    "          f\"\\nValidation dataset: {len(datasets['val'])} samples.\")\n",
    "\n",
    "    # Batch sizes\n",
    "    bsize_train = 4 # Training\n",
    "    bsize_val = 4 # Val and Test\n",
    "\n",
    "    # Prepare dataloaders\n",
    "    # Set SHUFFLE==FALSE\n",
    "    data_loaders = {'train' : DataLoader(datasets['train'], batch_size=bsize_train, shuffle=False, num_workers=0),\n",
    "                    'val'   : DataLoader(datasets['val'],  batch_size=bsize_val, shuffle=False, num_workers=0)}  \n",
    "\n",
    "    # Run prediction on training and validation datasets:\n",
    "    losses, accuracies, pred_labels = predict_check(data_loaders, model_ft,device=device)\n",
    "else:\n",
    "    print('Skipping train/validation set performances.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T10:35:29.934217Z",
     "start_time": "2020-11-01T10:35:14.983988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 292 images in test dataset folder: ./datasets/test_image/test_image\n",
      "\"0.png\"\n",
      "\"1.png\"\n",
      "\"2.png\"\n",
      ". . .\n",
      "\"289.png\"\n",
      "\"290.png\"\n",
      "\"291.png\"]\n",
      "\n",
      "Processing 73 test batches in total (batch_size=4).\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "pred_labels = predict_test(test_path, model_ft, test_transform, batch_size=4, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T10:37:03.566103Z",
     "start_time": "2020-11-01T10:37:03.183136Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write to csv file:\n",
    "preds_df = pd.DataFrame(data=pred_labels).sort_values('ID') # to pd.DataFrame\n",
    "preds_df.set_index('ID').to_csv('./test_submission.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
